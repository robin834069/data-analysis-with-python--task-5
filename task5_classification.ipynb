{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# DATA ANALYSIS AND DATA SCIENCE WITH PYTHON\n", "## Task 5 \u2013 Classification Tasks Overview\n", "\n", "This notebook contains the complete implementation of **Task 5**:\n", "\n", "1. **Student Pass/Fail Prediction** using Logistic Regression\n", "2. **Sentiment Analysis with Natural Language Processing (NLP)** using Logistic Regression\n", "\n", "The work is done in a clean, step\u2011by\u2011step, and professional manner, ready for submission and upload to GitHub."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Table of Contents\n", "1. [Setup and Common Imports](#setup)\n", "2. [Task 1 \u2013 Student Pass/Fail Prediction](#task1)\n", "    1. [Objective](#task1_objective)\n", "    2. [Dataset Creation](#task1_dataset)\n", "    3. [Data Exploration](#task1_explore)\n", "    4. [Feature Selection and Train\u2013Test Split](#task1_split)\n", "    5. [Model Training \u2013 Logistic Regression](#task1_model)\n", "    6. [Model Evaluation](#task1_evaluation)\n", "    7. [Insights](#task1_insights)\n", "3. [Task 2 \u2013 Sentiment Analysis with NLP](#task2)\n", "    1. [Objective](#task2_objective)\n", "    2. [Dataset Creation / Loading](#task2_dataset)\n", "    3. [Text Preprocessing](#task2_preprocess)\n", "    4. [Text Vectorization (TF\u2011IDF)](#task2_vectorize)\n", "    5. [Model Training \u2013 Logistic Regression](#task2_model)\n", "    6. [Model Evaluation](#task2_evaluation)\n", "    7. [Insights and Examples](#task2_insights)\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["setup"]}, "source": ["## 1. Setup and Common Imports <a id='setup'></a>\n", "\n", "Here we import the libraries that will be used in both classification tasks."]}, {"cell_type": "code", "metadata": {}, "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n", "\n", "sns.set(style=\"whitegrid\", context=\"notebook\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## 2. Task 1 \u2013 Student Pass/Fail Prediction <a id='task1'></a>\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["task1_objective"]}, "source": ["### 2.1 Objective <a id='task1_objective'></a>\n", "\n", "Predict whether a student will **pass (1)** or **fail (0)** using:\n", "\n", "- **Study Hours**: Number of hours the student studies per week\n", "- **Attendance**: Percentage of classes attended\n", "\n", "We will use a **Logistic Regression** classification model."]}, {"cell_type": "markdown", "metadata": {"tags": ["task1_dataset"]}, "source": ["### 2.2 Dataset Creation <a id='task1_dataset'></a>\n", "\n", "For demonstration, we create a small synthetic dataset that follows a realistic pattern:\n", "- Students with **low study hours and low attendance** tend to fail.\n", "- Students with **high study hours and high attendance** tend to pass."]}, {"cell_type": "code", "metadata": {}, "source": ["# Create a synthetic dataset for student performance\n", "data_student = {\n", "    'Study_Hours': [5, 8, 10, 12, 15, 18, 20, 22, 25, 28, 30, 32, 35, 38, 40,\n", "                    6, 9, 11, 14, 16, 19, 21, 23, 26, 29, 31, 33, 36, 39, 7],\n", "    'Attendance': [40, 50, 55, 60, 65, 70, 75, 78, 80, 82, 85, 88, 90, 92, 95,\n", "                   42, 52, 58, 63, 68, 72, 76, 79, 83, 86, 89, 91, 93, 96, 45]\n", "}\n", "\n", "df_student = pd.DataFrame(data_student)\n", "\n", "# Define a simple rule to label pass/fail for illustration\n", "# If (Study_Hours >= 15 and Attendance >= 70) -> Pass (1), else Fail (0)\n", "df_student['Pass'] = ((df_student['Study_Hours'] >= 15) & (df_student['Attendance'] >= 70)).astype(int)\n", "\n", "df_student.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task1_explore"]}, "source": ["### 2.3 Data Exploration <a id='task1_explore'></a>\n", "\n", "We will:\n", "- Check for missing values\n", "- View summary statistics\n", "- Visualize the relationship between features and target"]}, {"cell_type": "code", "metadata": {}, "source": ["# Check for missing values\n", "df_student.isnull().sum()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Summary statistics\n", "df_student.describe()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Visualize Study Hours vs Attendance colored by Pass/Fail\n", "plt.figure(figsize=(7, 5))\n", "sns.scatterplot(data=df_student, x='Study_Hours', y='Attendance', hue='Pass', s=80)\n", "plt.title('Study Hours vs Attendance (Colored by Pass/Fail)')\n", "plt.xlabel('Study Hours per Week')\n", "plt.ylabel('Attendance (%)')\n", "plt.legend(title='Pass')\n", "plt.tight_layout()\n", "plt.show()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task1_split"]}, "source": ["### 2.4 Feature Selection and Train\u2013Test Split <a id='task1_split'></a>\n", "\n", "We use **Study_Hours** and **Attendance** as features (X) and **Pass** as the target (y)."]}, {"cell_type": "code", "metadata": {}, "source": ["# Feature matrix and target vector\n", "X_student = df_student[['Study_Hours', 'Attendance']]\n", "y_student = df_student['Pass']\n", "\n", "# Train-test split (80% training, 20% testing)\n", "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n", "    X_student, y_student, test_size=0.2, random_state=42\n", ")\n", "\n", "X_train_s.shape, X_test_s.shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task1_model"]}, "source": ["### 2.5 Model Training \u2013 Logistic Regression <a id='task1_model'></a>\n", "\n", "We train a **Logistic Regression** model on the training set."]}, {"cell_type": "code", "metadata": {}, "source": ["# Initialize and train the Logistic Regression model\n", "log_reg_student = LogisticRegression()\n", "log_reg_student.fit(X_train_s, y_train_s)\n", "\n", "# Predict on the test set\n", "y_pred_s = log_reg_student.predict(X_test_s)\n", "y_pred_s"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task1_evaluation"]}, "source": ["### 2.6 Model Evaluation <a id='task1_evaluation'></a>\n", "\n", "We evaluate the model using:\n", "- **Accuracy**\n", "- **Confusion Matrix**\n", "- **Classification Report** (precision, recall, F1\u2011score)"]}, {"cell_type": "code", "metadata": {}, "source": ["# Accuracy\n", "accuracy_s = accuracy_score(y_test_s, y_pred_s)\n", "print(f\"Accuracy: {accuracy_s:.2f}\")\n", "\n", "# Confusion matrix\n", "cm_s = confusion_matrix(y_test_s, y_pred_s)\n", "print(\"\\nConfusion Matrix:\\n\", cm_s)\n", "\n", "# Visualize confusion matrix\n", "plt.figure(figsize=(4, 3))\n", "sns.heatmap(cm_s, annot=True, fmt='d', cmap='Blues', cbar=False,\n", "            xticklabels=['Predicted Fail', 'Predicted Pass'],\n", "            yticklabels=['Actual Fail', 'Actual Pass'])\n", "plt.title('Confusion Matrix \u2013 Student Pass/Fail')\n", "plt.ylabel('Actual')\n", "plt.xlabel('Predicted')\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# Detailed classification report\n", "print(\"\\nClassification Report:\\n\")\n", "print(classification_report(y_test_s, y_pred_s))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task1_insights"]}, "source": ["### 2.7 Insights <a id='task1_insights'></a>\n", "\n", "- Students with **higher study hours** and **higher attendance** have a higher probability of passing.\n", "- The model separates the passing and failing students reasonably well, as seen in the scatter plot.\n", "- The confusion matrix and accuracy score indicate how well the model generalizes on unseen data.\n", "- In a real project, we could further improve the model by collecting more data and testing other algorithms."]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## 3. Task 2 \u2013 Sentiment Analysis with Natural Language Processing <a id='task2'></a>\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["task2_objective"]}, "source": ["### 3.1 Objective <a id='task2_objective'></a>\n", "\n", "Analyze customer reviews and classify the **sentiment** as **positive** or **negative** using:\n", "\n", "- Text preprocessing (cleaning, lowercasing, removing stopwords)\n", "- **TF\u2011IDF vectorization** for converting text to numerical features\n", "- **Logistic Regression** for classification\n", "- Evaluation using **Accuracy, Precision, Recall, and F1\u2011Score**"]}, {"cell_type": "markdown", "metadata": {"tags": ["task2_dataset"]}, "source": ["### 3.2 Dataset Creation / Loading <a id='task2_dataset'></a>\n", "\n", "In practice, you would load a dataset such as `reviews.csv` with columns:\n", "- `Review_Text`\n", "- `Sentiment`\n", "\n", "Here, for demonstration, we create a small sample dataset inline."]}, {"cell_type": "code", "metadata": {}, "source": ["# Sample customer reviews dataset\n", "data_reviews = {\n", "    'Review_Text': [\n", "        \"Amazing product, works great!\",\n", "        \"Very disappointing, waste of money.\",\n", "        \"I love it, highly recommended!\",\n", "        \"Terrible experience, will not buy again.\",\n", "        \"I am happy with the quality and service.\",\n", "        \"Not worth buying, very poor performance.\",\n", "        \"Excellent build and great performance.\",\n", "        \"Really bad customer support.\",\n", "        \"Good value for money.\",\n", "        \"Worst product I have ever used.\"\n", "    ],\n", "    'Sentiment': [\n", "        'positive', 'negative', 'positive', 'negative', 'positive',\n", "        'negative', 'positive', 'negative', 'positive', 'negative'\n", "    ]\n", "}\n", "\n", "df_reviews = pd.DataFrame(data_reviews)\n", "df_reviews.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task2_preprocess"]}, "source": ["### 3.3 Text Preprocessing <a id='task2_preprocess'></a>\n", "\n", "Preprocessing steps:\n", "- Remove punctuation and special characters\n", "- Convert text to lowercase\n", "- Remove stopwords\n", "- (Optionally) perform stemming or lemmatization\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import re\n", "import nltk\n", "from nltk.corpus import stopwords\n", "\n", "# Download stopwords (run once; comment out if already downloaded)\n", "nltk.download('stopwords')\n", "\n", "stop_words = set(stopwords.words('english'))\n", "\n", "def clean_text(text: str) -> str:\n", "    \"\"\"Clean the input text by removing non-letters, lowercasing, and removing stopwords.\"\"\"\n", "    # Keep only letters\n", "    text = re.sub('[^a-zA-Z]', ' ', text)\n", "    # Lowercase\n", "    text = text.lower()\n", "    # Tokenize\n", "    tokens = text.split()\n", "    # Remove stopwords\n", "    tokens = [word for word in tokens if word not in stop_words]\n", "    # Join back to string\n", "    return \" \".join(tokens)\n", "\n", "# Apply cleaning function\n", "df_reviews['Clean_Review'] = df_reviews['Review_Text'].apply(clean_text)\n", "df_reviews"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task2_vectorize"]}, "source": ["### 3.4 Text Vectorization (TF\u2011IDF) <a id='task2_vectorize'></a>\n", "\n", "We convert the cleaned text into numerical form using **TF\u2011IDF (Term Frequency\u2013Inverse Document Frequency)**."]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "# Initialize TF-IDF vectorizer\n", "tfidf = TfidfVectorizer()\n", "\n", "# Fit and transform the clean reviews\n", "X_reviews = tfidf.fit_transform(df_reviews['Clean_Review'])\n", "\n", "# Encode sentiment labels: positive -> 1, negative -> 0\n", "y_reviews = df_reviews['Sentiment'].map({'positive': 1, 'negative': 0})\n", "\n", "X_reviews.shape, y_reviews.shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task2_model"]}, "source": ["### 3.5 Train\u2013Test Split and Model Training <a id='task2_model'></a>\n", "\n", "We split the data into training and testing sets and train a **Logistic Regression** classifier."]}, {"cell_type": "code", "metadata": {}, "source": ["# Train-test split (80% training, 20% testing)\n", "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n", "    X_reviews, y_reviews, test_size=0.2, random_state=42\n", ")\n", "\n", "# Initialize and train the Logistic Regression model\n", "log_reg_reviews = LogisticRegression(max_iter=1000)\n", "log_reg_reviews.fit(X_train_r, y_train_r)\n", "\n", "# Predictions\n", "y_pred_r = log_reg_reviews.predict(X_test_r)\n", "y_pred_r"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task2_evaluation"]}, "source": ["### 3.6 Model Evaluation <a id='task2_evaluation'></a>\n", "\n", "We evaluate the sentiment analysis model using:\n", "- **Accuracy**\n", "- **Precision**\n", "- **Recall**\n", "- **F1\u2011Score**"]}, {"cell_type": "code", "metadata": {}, "source": ["accuracy_r = accuracy_score(y_test_r, y_pred_r)\n", "print(f\"Accuracy: {accuracy_r:.2f}\")\n", "\n", "print(\"\\nClassification Report:\\n\")\n", "print(classification_report(y_test_r, y_pred_r, target_names=['negative', 'positive']))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"tags": ["task2_insights"]}, "source": ["### 3.7 Insights and Example Predictions <a id='task2_insights'></a>\n", "\n", "- **Positive reviews** tend to contain words such as: *amazing, love, excellent, happy, good, value*.\n", "- **Negative reviews** contain words like: *disappointing, waste, terrible, not, worst, bad*.\n", "- TF\u2011IDF highlights words that are important for distinguishing between positive and negative classes.\n", "- Logistic Regression works well as a simple and interpretable baseline model for sentiment analysis.\n", "\n", "Below we test the model with a few custom review examples."]}, {"cell_type": "code", "metadata": {}, "source": ["# Helper function to predict sentiment for new reviews\n", "def predict_sentiment(review_text: str) -> str:\n", "    clean = clean_text(review_text)\n", "    vec = tfidf.transform([clean])\n", "    pred = log_reg_reviews.predict(vec)[0]\n", "    return 'positive' if pred == 1 else 'negative'\n", "\n", "sample_reviews = [\n", "    \"The product quality is outstanding and I am very satisfied.\",\n", "    \"This is a total waste of money and time.\",\n", "    \"Average experience, nothing special but not too bad either.\"\n", "]\n", "\n", "for r in sample_reviews:\n", "    print(f\"Review: {r}\\nPredicted Sentiment: {predict_sentiment(r)}\\n\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## 4. Summary of Deliverables\n", "\n", "### Task 1 \u2013 Student Pass/Fail Prediction\n", "- \u2705 **Classification Model**: Logistic Regression trained on Study Hours and Attendance\n", "- \u2705 **Evaluation Metrics**: Accuracy, Confusion Matrix, Classification Report\n", "- \u2705 **Insights**: Relationship between study habits, attendance, and passing probability\n", "\n", "### Task 2 \u2013 Sentiment Analysis with NLP\n", "- \u2705 **Preprocessed Dataset**: Cleaned text with stopwords removed\n", "- \u2705 **Text Vectorization**: TF\u2011IDF features\n", "- \u2705 **Classification Model**: Logistic Regression for sentiment classification\n", "- \u2705 **Evaluation Metrics**: Accuracy, Precision, Recall, F1\u2011Score\n", "- \u2705 **Insights**: Common patterns in positive and negative reviews + example predictions\n", "\n", "This notebook is ready to be used as a professional project submission and can be directly uploaded to GitHub."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}